{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multi-Directional Spread</b>\n",
    "<n>Use 'trace-back' and 'back-fill' method where shortest distance from points across firefront back to previous day shared line is calculated.\n",
    "\n",
    "1. Get smoothed interpolated daily perimeters \n",
    "2. Get shared fire-line Day1 & Day 2\n",
    "3. Points along front line and shared line \n",
    "4. Find shortest distance from front line back to shared line \n",
    "\n",
    "For days > 1 then shared fireline can be past two days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.overwriteoutput = True\n",
    "import arcpy.management as DM\n",
    "import arcpy.cartography as CA\n",
    "\n",
    "env.workspace = \"F:\\DriversFireProject\\TEMP\"\n",
    "\n",
    "import shutil\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import requests\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files based on directory and extension inputs \n",
    "def shpFiles(rootPath, ext):\n",
    "    emptyList = []\n",
    "    root = rootPath\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for names in files: \n",
    "            if names.endswith(ext) and not names.startswith(\"._\"):\n",
    "                emptyList.append(path + '\\\\' + names)\n",
    "    return(emptyList)\n",
    "\n",
    "# Create new folder in root path \n",
    "def createFolder(rootPath, folderName): \n",
    "    folderPath = os.path.join(rootPath, folderName) \n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "    return folderPath + \"\\\\\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def closest_point(point, points):\n",
    "    \"\"\" Find closest point from a list of points. \"\"\"\n",
    "    return points[cdist([point], points).argmin()]\n",
    "\n",
    "def match_value(df, col1, x, col2):\n",
    "    \"\"\" Match value x from col1 row to value in col2. \"\"\"\n",
    "    return df[df[col1] == x][col2].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import radians, degrees, sin, cos, asin, acos, sqrt\n",
    "# def calculateDistance(pointA, pointB):\n",
    "#     lat1 = math.radians(pointA[0])\n",
    "#     lat2 = math.radians(pointB[0])\n",
    "#     lon1 = math.radians(pointA[1])\n",
    "#     lon2 = math.radians(pointB[1])\n",
    "#     return 6371 * (\n",
    "#         acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon1 - lon2))\n",
    "#     )\n",
    "\n",
    "def calculate_initial_compass_bearing(pointA, pointB):\n",
    "    \"\"\"\n",
    "    Calculates the bearing between two points.\n",
    "    The formulae used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - `pointA: The tuple representing the latitude/longitude for the\n",
    "        first point. Latitude and longitude must be in decimal degrees\n",
    "      - `pointB: The tuple representing the latitude/longitude for the\n",
    "        second point. Latitude and longitude must be in decimal degrees\n",
    "    :Returns:\n",
    "      The bearing in degrees\n",
    "    :Returns Type:\n",
    "      float\n",
    "    \"\"\"\n",
    "    if (type(pointA) != tuple) or (type(pointB) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "\n",
    "    diffLong = math.radians(pointB[1] - pointA[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointA = (41.01293623, -122.04922577)\n",
    "pointB = (41.01176303, -122.03467066)\n",
    "calculate_initial_compass_bearing(pointB, pointA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interFiles = shpFiles(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP', '.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete days from simplified SHP if > 85% cumulative burned sum \n",
    "# first create DF with fires, year, day, area burned \n",
    "fire = []\n",
    "year = [] \n",
    "day = []\n",
    "area = [] \n",
    "\n",
    "for inter in interFiles: \n",
    "    print(inter)\n",
    "    nm = inter.split(\"\\\\\")\n",
    "    shpName = nm[-1]\n",
    "    nmm = shpName.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    if len(arcpy.ListFields(inter,\"FireName\"))== 0:  \n",
    "        arcpy.AddField_management(inter, \"FireName\", \"TEXT\") \n",
    "    if len(arcpy.ListFields(inter,\"Year\"))== 0:  \n",
    "        arcpy.AddField_management(inter, \"Year\", \"TEXT\") \n",
    "    if len(arcpy.ListFields(inter,\"BurnedArea\"))== 0:  \n",
    "        arcpy.AddField_management(inter, \"BurnedArea\", \"FLOAT\") \n",
    "        arcpy.CalculateField_management(inter, \"BurnedArea\", \"!SHAPE.AREA@HECTARES!\", \"PYTHON\")\n",
    "    with arcpy.da.UpdateCursor(inter, ['gridcode', 'BurnedArea', 'FireName', 'Year']) as cursor: \n",
    "        for row in cursor: \n",
    "            fire.append(fr)\n",
    "            year.append(yr)\n",
    "            day.append(row[0])\n",
    "            area.append(row[1])\n",
    "            row[2] = fr\n",
    "            row[3] = str(yr)\n",
    "            \n",
    "            cursor.updateRow(row)\n",
    "\n",
    "fireInfo = pd.DataFrame({'Fire': fire, 'Year':year, 'Day': day, 'Area':area})\n",
    "fireInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireInfo.to_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\FireInfo_RAW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fireInfo['Fire'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireCount = fireInfo.groupby(['Fire', 'Year'])\n",
    "cumudf = fireCount.agg({'Day' : ['count'] , 'Area' : ['sum']}).reset_index()\n",
    "cumudf.columns = ['Fire', 'Year', 'Original Total Days', 'Original Total Area']\n",
    "newDF = fireInfo.merge(cumudf, on=['Fire', 'Year'])\n",
    "newDF['Ratio'] = newDF['Area']  / newDF['Original Total Area'] \n",
    "newDF['cumsum'] = newDF.groupby(['Fire', 'Year'])['Ratio'].cumsum()\n",
    "#newDF = newDF[newDF['cumsum'] < .90]   \n",
    "newDF = newDF[(newDF['Original Total Days'] < 6) | (newDF['cumsum'] < .80)]\n",
    "newCount = newDF.groupby(['Fire', 'Year'])\n",
    "newCount = newCount.agg({'Day' : ['count'] , 'Area' : ['sum']}).reset_index()\n",
    "newCount.columns = ['Fire', 'Year', 'Filtered Total Days', 'Filtered Total Area']\n",
    "new = newDF.merge(newCount, on=['Fire', 'Year'])\n",
    "new.to_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\FireInfo_Filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out if days dont match days in new df \n",
    "# create new filtered_simplified folder \n",
    "for inter in interFiles: \n",
    "    print(inter)\n",
    "    nm = inter.split(\"\\\\\")\n",
    "    shpName = nm[-1]\n",
    "    nmm = shpName.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    with arcpy.da.UpdateCursor(inter, ['gridcode']) as cursor: \n",
    "        for row in cursor: \n",
    "            day = row[0]\n",
    "            result = (new.Fire == fr) & (new.Year == str(yr)) & (new.Day == int(day))\n",
    "            if not any(result) == True: \n",
    "                print('deleted: ' + str(day))\n",
    "                cursor.deleteRow()\n",
    "            else: \n",
    "                continue \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\FinalDF.csv', index_col=0)\n",
    "FinalDF = FinalDF[~FinalDF['Fire'].isin(['Colby', 'Cherokee'])]\n",
    "sample = FinalDF.groupby(['Fire', 'Year']).size().reset_index()\n",
    "fire = sample['Fire'].tolist()\n",
    "FIRES = sample['Fire'].tolist()\n",
    "YEARS =  sample['Year'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FIRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Bagleycomplex\", \"American\", \"Hirz\", \"Carr\", \"Mendocinocomplexranch\", \"County\",\n",
    "#2012, 2013, 2018, 2018, 2018, 2018,\n",
    "FIRES = [ \"Mendocinocomplexriver\", \"Ferguson\", \"Donnell\", \"Tubbs\", \"Atlas\", \"Nuns\", \"Happycampcomplexfryingpan\"]\n",
    "YEARS = [ 2018, 2018, 2018, 2017, 2017, 2017, 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstDayVectors(firstDay):\n",
    "    SQL1 = \"gridcode = {}\".format(firstDay)\n",
    "    FirstDayPoly = arcpy.MakeFeatureLayer_management(simp, DayPath + fr + \"_\" + str(yr) + str(firstDay) + \"_temp.shp\", SQL1)\n",
    "    poly = arcpy.EliminatePolygonPart_management(FirstDayPoly, DayPath + str(firstDay) +  \"_tempfilt.shp\", \n",
    "                                                             \"PERCENT\",\"\", 3, \"ANY\")\n",
    "    polyCursor = arcpy.da.SearchCursor(poly, [\"SHAPE@\"])\n",
    "    polyInfo = polyCursor.next()[0]\n",
    "\n",
    "    name = fr  + \"_\" +  str(yr) + \"_VII_M6.shp\"\n",
    "    ignition = os.path.join(ignitionPath, name)\n",
    "    \n",
    "    pointCursor = arcpy.da.SearchCursor(ignition, [\"SHAPE@X\", \"SHAPE@Y\"])\n",
    "    ignitionCoord = pointCursor.next()\n",
    "    ignitionX = ignitionCoord[0]\n",
    "    ignitionY = ignitionCoord[1]\n",
    "    \n",
    "    ignitionPoint = arcpy.PointGeometry(arcpy.Point(ignitionX, ignitionY))\n",
    "    \n",
    "    ansA = polyInfo.contains(ignitionPoint)\n",
    "    \n",
    "    if ansA == False: \n",
    "        ignition = arcpy.FeatureToPoint_management(poly, os.path.join(ignitionFoldr, name) , \"INSIDE\")\n",
    "    else: \n",
    "        ignition = arcpy.CopyFeatures_management(ignition, os.path.join(ignitionFoldr, name)) \n",
    "        \n",
    "    DayLINE = arcpy.MakeFeatureLayer_management(poly, DayPath + fr + \"_\" + str(yr) + \"_\" + str(firstDay) +\"_dayLine.shp\")\n",
    "    DayPoints = arcpy.GeneratePointsAlongLines_management(DayLINE, DayPath + fr + \"_\" + str(yr) + \"_\" + str(firstDay) +\"_DayPoints.shp\", \n",
    "                                                                  'DISTANCE', Distance= 0.0008)\n",
    "    \n",
    "    arcpy.AddField_management(ignition, \"StoreID\", \"LONG\")  \n",
    "    arcpy.CalculateField_management(ignition, \"StoreID\", '!FID!')\n",
    "    \n",
    "    nearTable = arcpy.arcpy.GenerateNearTable_analysis(DayPoints, ignition, CSVPath + fr + \"_\" + str(yr) + \"_\" +str(firstDay) +\"_NearTable.csv\",\n",
    "                                                               \"\", \"LOCATION\", \"ANGLE\", \"CLOSEST\")\n",
    "    out_feature_class = os.path.join(nearTablePath, fr + \"_\" + str(yr) + \"_\" + str(firstDay) +\"_NearTable.shp\")\n",
    "    nearTableSHP = arcpy.management.XYTableToPoint(nearTable, \n",
    "                                            out_feature_class, 'FROM_X', 'FROM_Y')\n",
    "    lines = arcpy.ba.DesireLines(nearTableSHP, ignition, DayPath + fr + \"_\" + str(yr) + \"_\" + str(firstDay) +\"_tempVectors.shp\",\n",
    "                                 \"NEAR_FID\", \"StoreID\", \"STRAIGHT_LINE_DISTANCE\", \"KILOMETERS\", None, \"AWAY_FROM_STORES\")\n",
    "    lines_Clipped = arcpy.Clip_analysis(lines, poly, VectorLinesPath + fr + \"_\" + str(yr) + \"_\" + str(firstDay) +\"_Vectors.shp\")\n",
    "    \n",
    "    arcpy.AddField_management(lines_Clipped, \"Fire\", \"TEXT\")  \n",
    "    arcpy.AddField_management(lines_Clipped, \"Year\", \"TEXT\")  \n",
    "    arcpy.AddField_management(lines_Clipped, \"JulianDay\", \"TEXT\")\n",
    "    arcpy.AddField_management(lines_Clipped, \"Direction\", \"FLOAT\")  \n",
    "    arcpy.AddField_management(lines_Clipped, \"GroupByDir\", \"SHORT\")  \n",
    "    with arcpy.da.UpdateCursor(lines_Clipped, ['Fire', 'Year', 'JulianDay', 'Direction', 'NEAR_X', 'NEAR_Y' , 'FROM_X', 'FROM_Y', 'GroupByDir']) as cursor:\n",
    "         for row in cursor:\n",
    "            row[0] = fr\n",
    "            row[1] = str(yr)\n",
    "            row[2] = str(firstDay)\n",
    "            row[3] = calculate_initial_compass_bearing(tuple((row[5], row[4])), tuple((row[7], row[6])))\n",
    "            if 0 <= row[3] < 22.5 or 337.5 < row[3] <= 360:  # NORTH\n",
    "                row[8] = 1\n",
    "            elif 22.5 <= row[3] < 67.5: # NORTHEAST\n",
    "                row[8] = 2\n",
    "            elif 67.5 <= row[3] < 112.5: # EAST \n",
    "                row[8] = 3\n",
    "            elif 112.5 <= row[3] < 157.5: #SOUTHEAST\n",
    "                row[8] = 4\n",
    "            elif 157.5 <= row[3] < 202.5: # SOUTH\n",
    "                row[8] = 5\n",
    "            elif 202.5 <= row[3] <= 247.5: # SOUTHWEST\n",
    "                row[8] = 6\n",
    "            elif 247.5 <= row[3] <= 292.5: # WEST\n",
    "                row[8] = 7\n",
    "            else: \n",
    "                row[8] = 8 # NORTHWEST\n",
    "            cursor.updateRow(row)\n",
    "    del row, cursor\n",
    "\n",
    "    arcpy.TableToTable_conversion(lines_Clipped, CSVPath, fr + \"_\" + str(yr) + \"_\" + str(firstDay) + \"_Final.csv\")\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(CSVPath, fr + \"_\" + str(yr) + \"_\" + str(firstDay) + \"_Final.csv\"), index_col=0)\n",
    "    df = df[['Fire', 'Year', 'JulianDay', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "    df.to_csv(os.path.join(CSVPath, fr + \"_\" + str(yr) + \"_\" + str(firstDay) + \"_Final.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FIRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rootPath = r'F:\\DriversFireProject'\n",
    "fireInfo = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\FireInfo_Filtered.csv', index_col=0)\n",
    "inpath  = os.path.join(rootPath,'NaturalNeighborResults', 'Daily', 'SimplifiedSHP')\n",
    "outpath = os.path.join(rootPath,'MultiSpread')\n",
    "ignitionPath = r'F:\\DriversFireProject\\Ignition\\Centroid'\n",
    "\n",
    "for i, (fr, yr) in enumerate(zip(FIRES[182:], YEARS[182:])): \n",
    "    print(i, fr, yr)    \n",
    "    yrPath = createFolder(outpath, str(yr))\n",
    "    frPath = createFolder(yrPath, fr)\n",
    "    tempPath = createFolder(frPath, \"Temp\")\n",
    "    ignitionFoldr = createFolder(frPath, \"Ignitions\")\n",
    "    CSVPath = createFolder(frPath,  \"CSV\")\n",
    "    DayPath = createFolder(frPath,  \"DayPoints\")\n",
    "    sharedPath = createFolder(frPath,  \"SharedPoints\")\n",
    "    nearTablePath = createFolder(frPath,  \"NearTable\")\n",
    "    VectorLinesPath = createFolder(frPath,  \"VectorLines\")\n",
    "    MergedAllVector = createFolder(frPath,  \"VectorLines_MergedAll\")\n",
    "    FinalCSVPath = createFolder(frPath,  \"FinalCSV\")\n",
    "    \n",
    "    simp = os.path.join(inpath, str(yr), fr, fr + \"_\" + str(yr) + '_NAT.shp')\n",
    "    \n",
    "    day = [] \n",
    "    field = \"gridcode\"\n",
    "    cursor = arcpy.SearchCursor(simp)\n",
    "    for row in cursor:\n",
    "        day.append(row.getValue(field))\n",
    "    \n",
    "    if len(day) > 1: \n",
    "        day = sorted(day)\n",
    "        dayPairs = list(zip(day, day[1:] + day[:1])) \n",
    "        dayPairs = dayPairs[:-1] \n",
    "        \n",
    "        for i, pairs in enumerate(dayPairs): \n",
    "            try: \n",
    "                print(pairs)\n",
    "                day1 = pairs[0]\n",
    "                day2 = pairs[1]\n",
    "                DayPath = createFolder(tempPath,  str(day2))\n",
    "                DayPolygons = createFolder(tempPath, \"DayPolygons\")\n",
    "\n",
    "                if i == 0: \n",
    "                    firstDayVectors(day1)\n",
    "                    # Copy features for first 2 day  \n",
    "                    SQL = \"gridcode = {} Or gridcode = {}\".format(day1,day2)\n",
    "                    polyTemp = arcpy.MakeFeatureLayer_management(simp, DayPath + str(day1) + str(day2) +  \"_daytemp.shp\", SQL)\n",
    "                    poly = arcpy.EliminatePolygonPart_management(polyTemp, DayPath + str(day1) + str(day2) +  \"_tempfilt.shp\", \n",
    "                                                                 \"PERCENT\",\"\", 3, \"ANY\")\n",
    "                    arcpy.CopyFeatures_management(poly, DayPolygons + \"DayPolygon_tempfilt_\" + str(i) + \".shp\")\n",
    "                    DayPerimeter = arcpy.MakeFeatureLayer_management(poly, DayPath + fr + \"_\" + str(yr) + \"_DayPerim_\" + str(day1) +\".shp\", \n",
    "                                                  \"\\\"gridcode\\\" = {}\".format(int(day2)))\n",
    "\n",
    "                else: \n",
    "\n",
    "                    # get day 1 of previous pair \n",
    "                    prevDay = dayPairs[i-1][0]\n",
    "\n",
    "                    # Copy features for first 2 day  \n",
    "                    SQL1 = \"gridcode = {}\".format(day1)\n",
    "                    PrevDayPoly = arcpy.MakeFeatureLayer_management(simp, DayPath + str(day1) + \"_sharetemp.shp\", SQL1)\n",
    "                    # dissolve prev day and day 1 \n",
    "                    pastDaysSHP = DayPolygons + \"DayPolygon_tempfilt_\" + str(i-1) + \".shp\"\n",
    "\n",
    "                    polymerged = arcpy.Merge_management([pastDaysSHP, PrevDayPoly], DayPolygons + \"DayPolygon_tempfilt_\" + str(i) + \".shp\")\n",
    "\n",
    "                    dissolved = arcpy.Dissolve_management(polymerged, DayPath + str(day1) + \"_Distemp.shp\",\n",
    "                              [\"FID\"])\n",
    "\n",
    "                    SQL2 = \"gridcode = {}\".format(day2)\n",
    "                    Day2poly = arcpy.MakeFeatureLayer_management(simp, DayPath + str(day2) +  \"_temp.shp\", SQL2)\n",
    "                    polyElim = arcpy.EliminatePolygonPart_management(Day2poly, DayPath + str(day1) + str(day2) +  \"_tempfilt.shp\", \n",
    "                                                                 \"PERCENT\",\"\", 2, \"ANY\")\n",
    "\n",
    "                    # merge with day 2\n",
    "                    poly = arcpy.Merge_management([dissolved, polyElim], DayPath + str(day1) + str(day2) +  \"_temp.shp\")\n",
    "        #                 poly = arcpy.EliminatePolygonPart_management(polyTemp, DayPath + str(day1) + str(day2) +  \"_tempfilt.shp\", \n",
    "        #                                                              \"PERCENT\",\"\", 3, \"ANY\")\n",
    "                    DayPerimeter = arcpy.MakeFeatureLayer_management(poly, DayPath + fr + \"_\" + str(yr) + \"_DayPerim_\" + str(day1) +\".shp\", \n",
    "                                                  \"\\\"gridcode\\\" = {}\".format(int(day2)))\n",
    "\n",
    "\n",
    "                # 3. Convert to line \n",
    "                polyline = arcpy.PolygonToLine_management(poly, DayPath + fr + \"_\" + str(yr) +  \"_shareLine_\" + str(pairs[0]) + \"_\" + str(pairs[1]) +\".shp\")\n",
    "\n",
    "                # 4. Extract only shared line where LEFT_FID != -1 \n",
    "                sharedLine = arcpy.MakeFeatureLayer_management(polyline, DayPath + fr + \"_\" + str(yr) + \"_Sharedtemp_\" + str(pairs[1]) +\".shp\", \n",
    "                                                  \"\\\"LEFT_FID\\\" > -1\")\n",
    "\n",
    "                arcpy.CopyFeatures_management(sharedLine, tempPath + fr + \"_\" + str(yr) +\"_SharedLine_\" + str(pairs[1]) +\".shp\")\n",
    "\n",
    "                # if closed loop for shape-length < 0.01 Then delete for sharedline only \n",
    "        #             multishared = arcpy.MultipartToSinglepart_management(sharedLine,\n",
    "        #                                        tempPath + fr + \"_\" + str(yr) +\"_ShareLineMulti_\" + str(pairs[1]) +\".shp\")\n",
    "\n",
    "                arcpy.AddField_management(sharedLine, \"Length\", \"DOUBLE\") \n",
    "                arcpy.CalculateField_management(sharedLine, \"Length\", '!shape.length!')\n",
    "\n",
    "                # snap the features really close together to make one closed loop \n",
    "\n",
    "                #arcpy.CalculateGeometryAttributes_management(multiDay, [[\"Shape_Length\", \"LENGTH_GEODESIC\"]])\n",
    "\n",
    "                rows = arcpy.da.UpdateCursor(sharedLine, [\"Shape@\", \"Length\"])  \n",
    "                for rw in rows:  \n",
    "                    geom = rw[0]\n",
    "                    if geom.firstPoint.X == geom.lastPoint.X and rw[1] < 0.01:  \n",
    "                        rows.deleteRow()\n",
    "                del rw, rows  \n",
    "\n",
    "                # 5. Extract firefront  where RIGHT_FID != max\n",
    "                cursor = arcpy.da.SearchCursor(polyline, (\"RIGHT_FID\"))\n",
    "\n",
    "                RFID = []\n",
    "                for row in cursor:\n",
    "                    RFID.append(row[0])\n",
    "                del row, cursor\n",
    "\n",
    "                DayLINE = arcpy.MakeFeatureLayer_management(polyline, DayPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_dayLine.shp\", \n",
    "                                                  \"\\\"RIGHT_FID\\\" = {}\".format(max(RFID)))\n",
    "\n",
    "                arcpy.CopyFeatures_management(DayLINE, tempPath + fr + \"_\" + str(yr) + str(pairs[1]) +\"_dayLine.shp\") \n",
    "\n",
    "        #             # if closed loop for shape-length > 0.01 Then delete for dayline only \n",
    "        #             multiDay = arcpy.MultipartToSinglepart_management(DayLINE,\n",
    "        #                                        tempPath + fr + \"_\" + str(yr) +\"_DayLineMulti_\" + str(pairs[1]) +\".shp\")\n",
    "\n",
    "                arcpy.AddField_management(DayLINE, \"Length\", \"DOUBLE\") \n",
    "                arcpy.CalculateField_management(DayLINE, \"Length\", '!shape.length!')\n",
    "\n",
    "                #arcpy.CalculateGeometryAttributes_management(multiDay, [[\"Shape_Length\", \"LENGTH_GEODESIC\"]])\n",
    "\n",
    "                rows = arcpy.da.UpdateCursor(DayLINE, [\"Shape@\", \"Length\"])  \n",
    "                for rw in rows:  \n",
    "                    geom = rw[0]\n",
    "                    if geom.firstPoint.X == geom.lastPoint.X and rw[1] < 0.1:  \n",
    "                        rows.deleteRow()\n",
    "                del rw, rows \n",
    "\n",
    "                # 6. Create points along firefront  \n",
    "\n",
    "                DayPoints = arcpy.GeneratePointsAlongLines_management(DayLINE, \n",
    "                                                                      DayPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_DayPoints.shp\", \n",
    "                                                                      'DISTANCE', Distance= 0.0008)\n",
    "\n",
    "                # 7. Create points along shared line \n",
    "                sharedPoints = arcpy.GeneratePointsAlongLines_management(sharedLine, \n",
    "                                                                      sharedPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_SharedPoints.shp\", \n",
    "                                                                      'DISTANCE', Distance= 0.0008)\n",
    "\n",
    "                # 8. Create NearTable \n",
    "\n",
    "                nearTable = arcpy.arcpy.GenerateNearTable_analysis(DayPoints, sharedPoints, nearTablePath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_NearTable.csv\",\n",
    "                                                                   \"\", \"LOCATION\", \"ANGLE\", \"CLOSEST\")\n",
    "\n",
    "                arcpy.AddField_management(sharedPoints, \"StoreID\", \"LONG\")  \n",
    "                arcpy.CalculateField_management(sharedPoints, \"StoreID\", '!FID!')\n",
    "                arcpy.AddXY_management(sharedPoints)\n",
    "\n",
    "                arcpy.TableToTable_conversion(sharedPoints, CSVPath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_sharedPoints.csv\")\n",
    "                sharedDF = pd.read_csv(os.path.join(CSVPath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_sharedPoints.csv\"), index_col=0)\n",
    "                nearDF = pd.read_csv(os.path.join(nearTablePath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_NearTable.csv\"), index_col=0)\n",
    "\n",
    "                nearDF = nearDF.sort_values(by=['NEAR_FID'])\n",
    "                sharedDF = sharedDF.sort_values(by=['StoreID'])\n",
    "\n",
    "                fromX = [] \n",
    "                fromY = [] \n",
    "                nearX = [] \n",
    "                nearY = [] \n",
    "                nearFID = [] \n",
    "\n",
    "                IDList = sharedDF['StoreID'].tolist()\n",
    "                NearList = nearDF['NEAR_FID'].tolist()\n",
    "\n",
    "                notInList = [x for x in IDList if x not in NearList]\n",
    "\n",
    "                for idVAL in notInList:\n",
    "                    i = sharedDF.StoreID[sharedDF.StoreID == idVAL].index[0]\n",
    "                    shareX = sharedDF['POINT_X'][i]\n",
    "                    shareY = sharedDF['POINT_Y'][i]\n",
    "                    nearX.append(shareX)\n",
    "                    nearY.append(shareY)\n",
    "                    nearFID.append(sharedDF['StoreID'][i])\n",
    "\n",
    "                    nearDF['point'] = [(x, y) for x,y in zip(nearDF['NEAR_X'], nearDF['NEAR_Y'])]\n",
    "                    point = (shareX, shareY)\n",
    "                    closePT = closest_point(point, list(nearDF['point']))\n",
    "\n",
    "                    frmX = nearDF.loc[(nearDF['NEAR_X'] == closePT[0]) & (nearDF['NEAR_Y'] == closePT[1]), 'FROM_X'].iloc[0]\n",
    "                    frmY = nearDF.loc[(nearDF['NEAR_X'] == closePT[0]) & (nearDF['NEAR_Y'] == closePT[1]), 'FROM_Y'].iloc[0]\n",
    "                    fromX.append(frmX) \n",
    "                    fromY.append(frmY)\n",
    "\n",
    "                frame1 = pd.DataFrame({'NEAR_FID': nearFID, 'NEAR_X': nearX,'NEAR_Y': nearY, 'FROM_X': fromX, 'FROM_Y': fromY})\n",
    "                nearDF = nearDF[['NEAR_FID','NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "\n",
    "                frames = [nearDF, frame1]\n",
    "                result = pd.concat(frames)\n",
    "\n",
    "                result['Fire'] = fr\n",
    "                result['Year'] = str(yr)\n",
    "                result['JulianDay'] = str(pairs[1])\n",
    "                nearxy = list(zip(result['NEAR_Y'], result['NEAR_X'])) \n",
    "                fromxy = list(zip(result['FROM_Y'], result['FROM_X'])) \n",
    "\n",
    "                direction = []\n",
    "                for xy in zip(nearxy, fromxy):\n",
    "                    direction.append(calculate_initial_compass_bearing(xy[0], xy[1]))\n",
    "\n",
    "                result['Direction'] = direction\n",
    "\n",
    "                result.to_csv(CSVPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_complete.csv\")\n",
    "                result = result.sort_values(by=['NEAR_FID'])\n",
    "                out_feature_class = os.path.join(nearTablePath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_NearTable.shp\")\n",
    "                nearTableSHP = arcpy.management.XYTableToPoint(CSVPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_complete.csv\", \n",
    "                                                out_feature_class, 'FROM_X', 'FROM_Y')\n",
    "\n",
    "                lines = arcpy.ba.DesireLines(nearTableSHP, sharedPoints, DayPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_Vectors.shp\",\n",
    "                                     \"NEAR_FID\", \"StoreID\", \"STRAIGHT_LINE_DISTANCE\", \"KILOMETERS\", None, \"AWAY_FROM_STORES\")\n",
    "                lines_Clipped = arcpy.Clip_analysis(lines, DayPerimeter, VectorLinesPath + fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_Vectors.shp\")\n",
    "\n",
    "                arcpy.AddField_management(lines_Clipped, \"GroupByDir\", \"SHORT\")  \n",
    "                with arcpy.da.UpdateCursor(lines_Clipped, ['Direction','GroupByDir']) as cursor:\n",
    "                     for row in cursor:\n",
    "                        if 0 <= row[0] < 22.5 or 337.5 < row[0] <= 360:  # NORTH\n",
    "                            row[1] = 1\n",
    "                        elif 22.5 <= row[0] < 67.5: # NORTHEAST\n",
    "                            row[1] = 2\n",
    "                        elif 67.5 <= row[0] < 112.5: # EAST \n",
    "                            row[1] = 3\n",
    "                        elif 112.5 <= row[0] < 157.5: #SOUTHEAST\n",
    "                            row[1] = 4\n",
    "                        elif 157.5 <= row[0] < 202.5: # SOUTH\n",
    "                            row[1] = 5\n",
    "                        elif 202.5 <= row[0] <= 247.5: # SOUTHWEST\n",
    "                            row[1] = 6\n",
    "                        elif 247.5 <= row[0] <= 292.5: # WEST\n",
    "                            row[1] = 7\n",
    "                        else: \n",
    "                            row[1] = 8 # NORTHWEST\n",
    "                        cursor.updateRow(row)\n",
    "                del row, cursor\n",
    "\n",
    "                # to CSV \n",
    "                arcpy.TableToTable_conversion(lines_Clipped, CSVPath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_Final.csv\")\n",
    "\n",
    "                df = pd.read_csv(os.path.join(CSVPath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_Final.csv\"), index_col=0)\n",
    "                df = df[['Fire', 'Year', 'JulianDay', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "                df.to_csv(os.path.join(CSVPath, fr + \"_\" + str(yr) + \"_\" + str(pairs[1]) +\"_Final.csv\"))\n",
    "\n",
    "                shpList = shpFiles(VectorLinesPath, \".shp\")\n",
    "                if len(shpList) == len(dayPairs) + 1: \n",
    "                    merged = arcpy.Merge_management(shpList, os.path.join(MergedAllVector, fr + \"_\" + str(yr) + \"_Vec.shp\"))\n",
    "                    arcpy.TableToTable_conversion(merged, FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\")\n",
    "                    finaldf = pd.read_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"), index_col=0)\n",
    "                    finaldf = finaldf.merge(fireInfo, how = \"left\", left_on=['Fire', 'Year', 'JulianDay'], right_on=['Fire', 'Year', 'Day'])\n",
    "                    finaldf = finaldf[['Fire', 'Year', 'JulianDay', 'Area', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "                    finaldf.to_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"))\n",
    "            except: \n",
    "                print(\"error: \", pairs)\n",
    "                continue\n",
    "    elif len(day) == 1: \n",
    "        Cursor = arcpy.da.SearchCursor(simp,[\"gridcode\"])\n",
    "        day1 = Cursor.next()[0]\n",
    "        firstDayVectors(day1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fires with only one day copy files into VectorLines_MergedALL folder and add csv into FinalCSV folder \n",
    "# for fires with error, if folder empty and vectorfolder len > 1 then merge into folder and add CSV \n",
    "\n",
    "rootPath = r'F:\\DriversFireProject'\n",
    "fireInfo = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\FireInfo_Filtered.csv', index_col=0)\n",
    "inpath  = os.path.join(rootPath,'NaturalNeighborResults', 'Daily', 'SimplifiedSHP')\n",
    "outpath = os.path.join(rootPath,'MultiSpread')\n",
    "ignitionPath = r'F:\\DriversFireProject\\Ignition\\Centroid'\n",
    "\n",
    "for i, (fr, yr) in enumerate(zip(FIRES, YEARS)): \n",
    "    yrPath = createFolder(outpath, str(yr))\n",
    "    frPath = createFolder(yrPath, fr)\n",
    "    VectorLinesPath = createFolder(frPath, \"VectorLines\")\n",
    "    MergedAllVector = createFolder(frPath, \"VectorLines_MergedAll\")\n",
    "    FinalCSVPath = createFolder(frPath, \"FinalCSV\")\n",
    "    if len(os.listdir(MergedAllVector)) == 0:\n",
    "        print(fr, yr)\n",
    "        try: \n",
    "            shpList = shpFiles(VectorLinesPath, '.shp')\n",
    "            if len(shpList) == 1:\n",
    "                # copy features management \n",
    "                copy = arcpy.CopyFeatures_management(shpList[0], os.path.join(MergedAllVector, fr + \"_\" + str(yr) + \"_Vec.shp\"))\n",
    "                arcpy.TableToTable_conversion(copy, FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\")\n",
    "                finaldf = pd.read_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"), index_col=0)\n",
    "                finaldf = finaldf.merge(fireInfo, how = \"left\", left_on=['Fire', 'Year', 'JulianDay'], right_on=['Fire', 'Year', 'Day'])\n",
    "                finaldf = finaldf[['Fire', 'Year', 'JulianDay', 'Area', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "                # add csv \n",
    "                finaldf.to_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"))\n",
    "\n",
    "            elif len(shpList) > 1:\n",
    "                # merge features management \n",
    "                merged = arcpy.Merge_management(shpList, os.path.join(MergedAllVector, fr + \"_\" + str(yr) + \"_Vec.shp\"))\n",
    "                arcpy.TableToTable_conversion(merged, FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\")\n",
    "                finaldf = pd.read_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"), index_col=0)\n",
    "                finaldf = finaldf.merge(fireInfo, how = \"left\", left_on=['Fire', 'Year', 'JulianDay'], right_on=['Fire', 'Year', 'Day'])\n",
    "                finaldf = finaldf[['Fire', 'Year', 'JulianDay', 'Area', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "                # add csv \n",
    "                finaldf.to_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"))\n",
    "            else: \n",
    "                print(fr, yr, 'none')\n",
    "        except: \n",
    "            print(fr, yr, 'error')\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = r'F:\\DriversFireProject'\n",
    "fireInfo = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\FireInfo_Filtered.csv', index_col=0)\n",
    "inpath  = os.path.join(rootPath,'NaturalNeighborResults', 'Daily', 'SimplifiedSHP')\n",
    "outpath = os.path.join(rootPath,'MultiSpread')\n",
    "\n",
    "for i, (fr, yr) in enumerate(zip(FIRES, YEARS)): \n",
    "    yrPath = createFolder(outpath, str(yr))\n",
    "    frPath = createFolder(yrPath, fr)\n",
    "    VectorLinesPath = createFolder(frPath, \"VectorLines\")\n",
    "    MergedAllVector = createFolder(frPath, \"VectorLines_MergedAll\")\n",
    "    FinalCSVPath = createFolder(frPath, \"FinalCSV\")\n",
    "    if len(os.listdir(FinalCSVPath)) == 0:\n",
    "        print(fr, yr)\n",
    "        try:\n",
    "            copy = os.path.join(MergedAllVector, fr + \"_\" + str(yr) + \"_Vec.shp\")\n",
    "            arcpy.TableToTable_conversion(copy, FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\")\n",
    "            finaldf = pd.read_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"), index_col=0)\n",
    "            finaldf = finaldf.merge(fireInfo, how = \"left\", left_on=['Fire', 'Year', 'JulianDay'], right_on=['Fire', 'Year', 'Day'])\n",
    "            finaldf = finaldf[['Fire', 'Year', 'JulianDay', 'Area', 'Direction', 'GroupByDir', 'Distance', 'NEAR_X', 'NEAR_Y', 'FROM_X', 'FROM_Y']]\n",
    "            # add csv \n",
    "            finaldf.to_csv(os.path.join(FinalCSVPath, fr + \"_\" + str(yr) + \"_FinalAll.csv\"))\n",
    "        except: \n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
