{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\CumuDayLayer' \n",
    "# these layers only contain up to 85% of fire burned \n",
    "# create convexhull and calculate geometry (major.minor axis) for each cumulative day \n",
    "# take minor/major ratio and determine threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.overwriteoutput = True\n",
    "\n",
    "env.workspace = \"F:\\DriversFireProject\\TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import requests\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files based on directory and extension inputs \n",
    "def shpFiles(rootPath, ext):\n",
    "    emptyList = []\n",
    "    root = rootPath\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for names in files: \n",
    "            if names.endswith(ext) and not names.startswith(\"._\"):\n",
    "                emptyList.append(path + '\\\\' + names)\n",
    "    return(emptyList)\n",
    "\n",
    "# Create new folder in root path \n",
    "def createFolder(rootPath, folderName): \n",
    "    folderPath = os.path.join(rootPath, folderName) \n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "    return folderPath + \"\\\\\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumuShp = shpFiles(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\CumuDayLayer' , '.shp')\n",
    "cumuShp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outpath = r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\ConvexHull\\\\'\n",
    "\n",
    "fire = [] \n",
    "year = [] \n",
    "julianDay = [] \n",
    "MajorAxis = [] \n",
    "MinorAxis = [] \n",
    "Ratio = [] \n",
    "\n",
    "for cumu in cumuShp: \n",
    "    nm = cumu.split(\"\\\\\")\n",
    "    name = nm[-1]\n",
    "    nmm = name.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    jd = nmm[2]\n",
    "    yrfolder = outpath + str(yr)\n",
    "    if not os.path.exists(yrfolder):\n",
    "        os.makedirs(yrfolder)\n",
    "    fireFolder = yrfolder + \"\\\\\" + fr\n",
    "    if not os.path.exists(fireFolder):\n",
    "        os.makedirs(fireFolder)\n",
    "    # Use MinimumBoundingGeometry function to get a convex hull area\n",
    "    #for each cluster of trees which are multipoint features\n",
    "    convex = arcpy.MinimumBoundingGeometry_management(cumu, fireFolder + \"\\\\\" + name, \n",
    "                                         \"CONVEX_HULL\", \"ALL\", \"\", \"MBG_FIELDS\")\n",
    "    with arcpy.da.SearchCursor(convex, ['MBG_Width', 'MBG_Length',]) as cursor:\n",
    "            for row in cursor:\n",
    "                try: \n",
    "                    Ratio.append(row[0]/row[1])\n",
    "                    MajorAxis.append(row[0])\n",
    "                    MinorAxis.append(row[1])\n",
    "                    fire.append(fr) \n",
    "                    year.append(yr) \n",
    "                    julianDay.append(jd)\n",
    "                    print(yr, fr, row[0]/row[1])\n",
    "                except: \n",
    "                    continue\n",
    "                \n",
    "AxisDF = pd.DataFrame({'Fire': fire, 'Year': year,'JulianDay': julianDay, \n",
    "                       'MajorAxis': MajorAxis, 'MinorAxis': MinorAxis, 'Ratio':Ratio})\n",
    "AxisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AxisDF.to_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\MajorMinorAxisRatio_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AxisDF = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\MajorMinorAxisRatio_DF.csv', index_col=0)\n",
    "AxisDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\FinalDF.csv', index_col=0)\n",
    "FinalDF = FinalDF[['Fire', 'Year','JD_B', 'Area(ha)', 'direction', 'distance', 'FID_ca_eco', 'EcoRegion']]\n",
    "#FinalDF['Year'] = FinalDF['Year'].astype(str)\n",
    "#FinalDF['JD_B'] = FinalDF['JD_B'].astype(str)\n",
    "Finalmerged = pd.merge(AxisDF,FinalDF, how='left',left_on=['Fire','Year', 'JulianDay'], right_on=['Fire','Year', 'JD_B'])\n",
    "Finalmerged['Ratio']  = Finalmerged['Ratio'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedbyFire = Finalmerged.groupby(['FID_ca_eco', 'EcoRegion', 'Fire'])['Ratio'].agg('median').reset_index()\n",
    "MergedbyFire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first day shapes \n",
    "idx = Finalmerged.groupby(['FID_ca_eco', 'EcoRegion', 'Fire'])['JulianDay'].transform(min) == Finalmerged['JulianDay']\n",
    "firstDay = Finalmerged[idx]\n",
    "firstDay.groupby(['FID_ca_eco', 'EcoRegion'])['Ratio'].agg(['median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last day shapes\n",
    "idx = Finalmerged.groupby(['FID_ca_eco', 'EcoRegion', 'Fire'])['JulianDay'].transform(max) == Finalmerged['JulianDay']\n",
    "lastDay = Finalmerged[idx]\n",
    "lastDay.groupby(['FID_ca_eco', 'EcoRegion'])['Ratio'].agg(['median']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(lastDay, col=\"EcoRegion\")\n",
    "g = g.map(plt.scatter, \"MajorAxis\", \"MinorAxis\", edgecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"FID_ca_eco\", y=\"Ratio\",\n",
    "            hue=\"EcoRegion\",\n",
    "            data=firstDay)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"FID_ca_eco\", y=\"Ratio\",\n",
    "            hue=\"EcoRegion\",\n",
    "            data=lastDay)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge NIROPS shapefiles and interpolated files. \n",
    "nirops = shpFiles(r'F:\\DriversFireProject\\Merged_Daily_DIFF', '.shp')\n",
    "interFiles = shpFiles(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\Dis_Shapefile', '.shp')\n",
    "arcpy.Merge_management(interFiles, r\"F:\\DriversFireProject\\GEE_Dataset\\Interpolated_ALL.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POST-PROCESSING: Simplify and smooth out interpolated surfaces\n",
    "    1. PAEK smooth polygon; 10 deg \n",
    "    2. Eliminate Polygon Part; Contained Parts only, 0.001 deg \n",
    "    3. Convert to raster \n",
    "    4. Focal Stats 3x3 smoothing \n",
    "    5. Convert back to shp; simplify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interFiles = shpFiles(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\Dis_Shapefile', '.shp')\n",
    "lastDayPath = r'F:\\DriversFireProject\\LastDayPerimeters\\\\'\n",
    "outpath = r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\SimplifiedSHP\\\\'\n",
    "for inter in interFiles: \n",
    "    nm = inter.split(\"\\\\\")\n",
    "    name = nm[-1]\n",
    "    nmm = name.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    print(fr, yr)\n",
    "    # create new folder paths \n",
    "    yrPath = createFolder(outpath, yr)\n",
    "    frPath = createFolder(yrPath, fr)\n",
    "    tempPath = createFolder(outpath, \"temp\")\n",
    "    try: \n",
    "        simp = arcpy.SmoothPolygon_cartography(inter, os.path.join(tempPath, fr + \"_\" + str(yr) + '_SIM.shp'), \"PAEK\", 10) \n",
    "        elim = arcpy.EliminatePolygonPart_management(simp, os.path.join(tempPath, fr + \"_\" + str(yr) + '_ELIM.shp'), \"AREA\", 0.001 , \"\", \"CONTAINED_ONLY\")\n",
    "        ras = arcpy.PolygonToRaster_conversion(elim, \"gridcode\", \n",
    "                                     os.path.join(tempPath, fr + \"_\" + str(yr) + '_RAS.tif'), \n",
    "                                     \"CELL_CENTER\", \"NONE\", 0.0015)\n",
    "        outFocalStat = FocalStatistics(ras, NbrCircle(8, \"CELL\"), \"MEDIAN\", \"DATA\")\n",
    "        lastDayShp = os.path.join(lastDayPath, str(yr), fr + \"_\" + str(yr) + '_Fire_ALL.shp') \n",
    "        outExtractByMask = ExtractByMask(outFocalStat, lastDayShp)\n",
    "        poly = arcpy.RasterToPolygon_conversion(outExtractByMask, os.path.join(tempPath, name) , \"SIMPLIFY\",\"VALUE\")\n",
    "        arcpy.Dissolve_management(poly, os.path.join(frPath, name), \"gridcode\", \"\", \"MULTI_PART\", \"DISSOLVE_LINES\")\n",
    "        shutil.rmtree(tempPath)\n",
    "    except: \n",
    "        print(\"error: \", fr, yr)\n",
    "        arcpy.CopyFeatures_management(inter, os.path.join(frPath,name))\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\FinalDF.csv', index_col=0)\n",
    "sample = FinalDF.groupby(['Fire', 'Year']).size().reset_index()\n",
    "fire = sample['Fire'].tolist()\n",
    "FIRES = sample['Fire'].tolist()\n",
    "YEARS =  sample['Year'].tolist()\n",
    "for y, f in zip(FIRES, YEARS): \n",
    "    print(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bufers for each instance where coordinate touches fireline \n",
    "# from buffer, intersect with shared line \n",
    "# get coordinate PNTC and intersect as point \n",
    "\n",
    "def NormalToLine(startPoint, endPoint):\n",
    "    # create buffer around PT A \n",
    "    buffName = tempPath + 'BUFF.shp'\n",
    "    pointA = arcpy.PointGeometry(arcpy.Point(startPoint[0], startPoint[1]), sr)\n",
    "    buff = arcpy.Buffer_analysis(pointA, buffName, 0.0001)\n",
    "\n",
    "    # intersect with lines[pl[0]]\n",
    "    InterName = tempPath + 'INTER.shp'\n",
    "    intersect = arcpy.Intersect_analysis([buff, disShared], InterName, \"\", \"\", \"POINT\")\n",
    "    # multi point to single point \n",
    "    intersectPT = arcpy.MultipartToSinglepart_management(intersect,\n",
    "                      tempPath + 'INTERPT.shp')\n",
    "    \n",
    "    # find point C \n",
    "    shape = arcpy.da.SearchCursor(intersectPT,[\"SHAPE@XY\"])\n",
    "    x, y = shape.next()[0]\n",
    "    \n",
    "        \n",
    "    #pointC = arcpy.PointGeometry(arcpy.Point(x, y), sr)\n",
    "#     distAC = startPoint.distanceTo(pointC)\n",
    "#     distBC = endPoint.distanceTo(pointC)\n",
    "#     distAB = startPoint.distanceTo(endPoint)\n",
    "\n",
    "    arcpy.Delete_management(buff)\n",
    "    arcpy.Delete_management(intersectPT)\n",
    "    arcpy.Delete_management(intersect)\n",
    "\n",
    "    # calculate theta = arccos(PAB * PAC / abs(PAB) abs(PAC)) \n",
    "#     angA = math.degrees(math.acos((((distAB*distAB)+(distAC*distAC))-(distBC*distBC))/(2*distBC*distAC)))\n",
    "    \n",
    "    a = np.array(endPoint)\n",
    "    b = np.array(startPoint)\n",
    "    c = np.array([x, y])\n",
    "\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    angA = np.degrees(angle)\n",
    "    #print(angA)\n",
    "    if 89 <= int(angA) <= 91:\n",
    "        return True \n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Smooth/Simplify merged interpolated perimeters\n",
    "# 2. Copy features @ 2 day interval \n",
    "# 3. Convert to line \n",
    "# 4. Extract only shared line where FID != -1 \n",
    "import arcpy.management as DM\n",
    "import arcpy.cartography as CA\n",
    "import itertools\n",
    "rootPath = r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily'\n",
    "\n",
    "inpath  = os.path.join(rootPath,'Dis_Shapefile')\n",
    "outpath = os.path.join(rootPath,'SpreadFiles')\n",
    "\n",
    "for fr, yr in zip(FIRES, YEARS): \n",
    "    print(fr, yr)    \n",
    "    yrPath = createFolder(outpath, str(yr))\n",
    "    frPath = createFolder(yrPath, fr)\n",
    "    tempPath = createFolder(frPath, \"Temp\")\n",
    "    \n",
    "    sampleSurface = os.path.join(inpath, str(yr), fr, fr + \"_\" + str(yr) + \"_NAT.shp\") \n",
    "    simp = os.path.join(rootPath, 'SimplifiedSHP', str(yr), fr, fr + \"_\" + str(yr) + '_NAT.shp')\n",
    "\n",
    "    day = [] \n",
    "    field = \"gridcode\"\n",
    "    cursor = arcpy.SearchCursor(simp)\n",
    "    for row in cursor:\n",
    "        day.append(row.getValue(field))\n",
    "    \n",
    "    if len(day) > 1: \n",
    "        day = sorted(day)\n",
    "        dayPairs = list(zip(day, day[1:] + day[:1])) \n",
    "        dayPairs = dayPairs[:-1] \n",
    "        for pairs in dayPairs: \n",
    "            try:\n",
    "                print(pairs)\n",
    "                startPT = [] \n",
    "                endPT = [] \n",
    "                JD = []\n",
    "                Fire = []\n",
    "                Year = []\n",
    "\n",
    "                day1 = pairs[0]\n",
    "                day2 = pairs[1]\n",
    "                # 2. Copy features @ 2 day interval \n",
    "                SQL = \"gridcode = {} Or gridcode = {}\".format(day1,day2)\n",
    "                poly = arcpy.MakeFeatureLayer_management(simp, tempPath + str(pairs[0]) + \"_\" + str(pairs[1]) + \"_temp.shp\", SQL)\n",
    "                # 3. Convert to line \n",
    "                polyline = arcpy.PolygonToLine_management(poly, tempPath + fr + \"_\" + str(yr) +  \"_Line_\" + str(pairs[0]) + \"_\" + str(pairs[1]) +\".shp\")\n",
    "\n",
    "                # 4. Extract only shared line where FID != -1 \n",
    "                sharedLine = arcpy.MakeFeatureLayer_management(polyline, tempPath + fr + \"_\" + str(yr) + \"_Sharedtemp_\" + str(pairs[1]) +\".shp\", \n",
    "                                                  \"\\\"LEFT_FID\\\" > -1\")\n",
    "\n",
    "                arcpy.CopyFeatures_management(sharedLine, tempPath + fr + \"_\" + str(yr) +\"_SharedLine_\" + str(pairs[1]) +\".shp\") \n",
    "\n",
    "                # 5. Generate perpendicular lines along shared line \n",
    "                transects = arcpy.GenerateTransectsAlongLines_management(sharedLine, tempPath + fr + \"_\" + str(yr) +  \"_Transects_\" + str(pairs[1]) +\".shp\",\n",
    "                                                         '0.001', '1','NO_END_POINTS')\n",
    "                SQL2 = \"gridcode = {}\".format(day2)\n",
    "                day2Poly = arcpy.MakeFeatureLayer_management(simp, tempPath + str(pairs[0]) + \"_\" + str(pairs[1]) + \"_temp2.shp\", SQL2)\n",
    "\n",
    "                # 6. Clip lines with day polygon and change multipart to singlepart \n",
    "                clipTrans = arcpy.Clip_analysis(transects, day2Poly, tempPath + fr + \"_\" + str(yr) +  \"_ClippedTrans_\" + str(pairs[1]) + \".shp\")\n",
    "\n",
    "                ClippedTransectsFolder = createFolder(frPath, \"ClippedTransects\" )\n",
    "\n",
    "                multi = arcpy.MultipartToSinglepart_management(clipTrans,\n",
    "                                                  ClippedTransectsFolder + fr + \"_\" + str(yr) +  \"_MultiTrans_\" + str(pairs[1]) + \".shp\")\n",
    "                arcpy.AddField_management(multi, \"POINT1_X\", \"DOUBLE\")\n",
    "                arcpy.AddField_management(multi, \"POINT1_Y\", \"DOUBLE\")\n",
    "                arcpy.AddField_management(multi, \"POINT2_X\", \"DOUBLE\")\n",
    "                arcpy.AddField_management(multi, \"POINT2_Y\", \"DOUBLE\")\n",
    "\n",
    "                arcpy.CalculateGeometryAttributes_management(multi, [[\"POINT1_X\", \"LINE_START_X\"],\n",
    "                                                                       [\"POINT1_Y\", \"LINE_START_Y\"],\n",
    "                                                                       [\"POINT2_X\", \"LINE_END_X\"],\n",
    "                                                                       [\"POINT2_Y\", \"LINE_END_Y\"]])\n",
    "                #sharedLine\n",
    "                sharedFolder = createFolder(frPath, \"SharedLine\")\n",
    "                sr = arcpy.Describe(sharedLine).spatialReference\n",
    "                #Loop through shareLine\n",
    "                # dissolve shared line into one \n",
    "                disShared = arcpy.Dissolve_management(sharedLine, sharedFolder + '\\\\' + fr + \"_\" + str(yr) +\"_SharedLine_\" + str(pairs[1]) +\".shp\",\n",
    "                              [\"FID\"], \"\", \"MULTI_PART\", \"DISSOLVE_LINES\")\n",
    "\n",
    "                disSharedCursor = arcpy.da.SearchCursor(disShared,[\"--\"])\n",
    "                line = disSharedCursor.next()[0]\n",
    "\n",
    "                with arcpy.da.UpdateCursor(multi, ['FID', 'ORIG_FID', 'POINT1_X', 'POINT1_Y', 'POINT2_X', 'POINT2_Y']) as cursor:\n",
    "                    for row in cursor:\n",
    "                        pointA = arcpy.PointGeometry(arcpy.Point(row[2], row[3]), sr)\n",
    "                        pointB = arcpy.PointGeometry(arcpy.Point(row[4], row[5]), sr)\n",
    "\n",
    "                        ansA = pointA.within(line)\n",
    "                        ansB = pointB.within(line)\n",
    "\n",
    "                        if ansA == True and ansB == True:\n",
    "                            # delete if both ends fall on shared fireline (concave or circular) \n",
    "                            #print(row[0], \" is deleted\")\n",
    "                            cursor.deleteRow()\n",
    "                        elif ansA == True and NormalToLine([row[2], row[3]], [row[4], row[5]]) == True: \n",
    "                            #print(row[0], \" satisfies requirements\")\n",
    "                            startPT.append(tuple((row[3], row[2])))\n",
    "                            endPT.append(tuple((row[5], row[4])))\n",
    "                            JD.append(day2)\n",
    "                            Fire.append(fr)\n",
    "                            Year.append(yr)\n",
    "                        elif ansB == True and NormalToLine([row[4], row[5]], [row[2], row[3]]) == True: \n",
    "                            #print(row[0], \" satisfies requirements\")\n",
    "                            endPT.append(tuple((row[3], row[2])))\n",
    "                            startPT.append(tuple((row[5], row[4])))\n",
    "                            JD.append(day2)\n",
    "                            Fire.append(fr)\n",
    "                            Year.append(yr)\n",
    "                        else: \n",
    "                            # delete if neither ends fall on shared fireline \n",
    "                            # also captures lines that are not perpendicular to fireline \n",
    "                            #print(row[0], \" is deleted\")\n",
    "                            cursor.deleteRow()\n",
    "\n",
    "\n",
    "\n",
    "                # Create csv file for each day and fire \n",
    "                CSVFolder = createFolder(frPath, \"CSV\")\n",
    "                multiDirDF = pd.DataFrame({'Fire': Fire, 'Year': Year,'JulianDay': JD, 'startPT': startPT, 'endPT': endPT})\n",
    "                multiDirDF.to_csv(CSVFolder + fr + \"_\" + str(yr) + \"_\" + str(day2) + '.csv')\n",
    "                # Delete files in temp folder \n",
    "                #shutil.rmtree(tempPath)\n",
    "                print(\"done\")\n",
    "            except: \n",
    "                continue\n",
    " \n",
    "    else:\n",
    "        print(\"Only one day: \", day)\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multiDirDF = pd.DataFrame({'Fire': Fire, 'Year': Year,'JulianDay': JD, \n",
    "                       'startPT': startPT, 'endPT': endPT})\n",
    "multiDirDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import radians, degrees, sin, cos, asin, acos, sqrt\n",
    "def calculateDistance(pointA, pointB):\n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "    lon1 = math.radians(pointA[1])\n",
    "    lon2 = math.radians(pointB[1])\n",
    "    return 6371 * (\n",
    "        acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon1 - lon2))\n",
    "    )\n",
    "\n",
    "def calculate_initial_compass_bearing(pointA, pointB):\n",
    "    \"\"\"\n",
    "    Calculates the bearing between two points.\n",
    "    The formulae used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - `pointA: The tuple representing the latitude/longitude for the\n",
    "        first point. Latitude and longitude must be in decimal degrees\n",
    "      - `pointB: The tuple representing the latitude/longitude for the\n",
    "        second point. Latitude and longitude must be in decimal degrees\n",
    "    :Returns:\n",
    "      The bearing in degrees\n",
    "    :Returns Type:\n",
    "      float\n",
    "    \"\"\"\n",
    "    if (type(pointA) != tuple) or (type(pointB) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(pointA[0])\n",
    "    lat2 = math.radians(pointB[0])\n",
    "\n",
    "    diffLong = math.radians(pointB[1] - pointA[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance and direction based on startPT and endPT \n",
    "direction = []\n",
    "distance = []\n",
    "for i, row in multiDirDF.iterrows():\n",
    "    direction.append(calculate_initial_compass_bearing(row.startPT, row.endPT))\n",
    "    distance.append(calculateDistance(row.startPT, row.endPT))\n",
    "\n",
    "multiDirDF['direction'] = direction\n",
    "multiDirDF['distance'] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiDirDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
