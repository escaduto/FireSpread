{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each day per fire save as new layer and cumulative layer \n",
    "# Create Buffer OUTSIDE_ONLY, ALL\n",
    "# [500m, 1km, 5km]\n",
    "# merge 3 buffers into one : FireName_JulianDay_Year.shp \n",
    "# Zonal Stats for all variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import io\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.overwriteoutput = True\n",
    "\n",
    "env.workspace = \"F:\\DriversFireProject\\TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that finds all shapefiles in root \n",
    "\n",
    "def lstFiles(rootPath, ext):\n",
    "    emptyList = []\n",
    "    root = rootPath\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for names in files: \n",
    "            if names.endswith(ext) and not names.startswith(\"._\"):\n",
    "                emptyList.append(path + '\\\\' + names)\n",
    "    return(emptyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finalmerged = pd.read_csv(r'F:\\DriversFireProject\\NaturalNeighborResults\\FinalDF.csv', index_col=0)\n",
    "Finalmerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAT_SHP = lstFiles(r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\Dis_Shapefile', \".shp\")\n",
    "NAT_SHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create buffers at ignition point locations to predict first day\n",
    "\n",
    "ignitionPoints = lstFiles(r'F:\\DriversFireProject\\Ignition\\Centroid', '.shp')\n",
    "rootpath = r'F:\\\\DriversFireProject\\\\NaturalNeighborResults\\\\Daily\\\\'\n",
    "\n",
    "for ignition in ignitionPoints:\n",
    "    nm = ignition.split(\"\\\\\")\n",
    "    outName = nm[-1]\n",
    "    nmm = outName.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    \n",
    "    buff_fireFolder = rootpath + 'MergedBuff\\\\' + yr + \"\\\\\" + fr\n",
    "    \n",
    "    print(ignition)\n",
    "    try: \n",
    "        Buffer_200M = arcpy.Buffer_analysis(ignition, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_0_200m.shp\",\n",
    "                              \"200 METERS\") \n",
    "        Buffer_1KM = arcpy.Buffer_analysis(ignition, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_0_1Km.shp\",\n",
    "                              \"1000 METERS\")     \n",
    "        Buffer_5KM = arcpy.Buffer_analysis(ignition, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_0_5Km.shp\",\n",
    "                              \"5000 METERS\")    \n",
    "        arcpy.Merge_management([Buffer_200M, Buffer_1KM, Buffer_5KM], buff_fireFolder + \"\\\\\" + fr + \"_\" + yr + \"_0_NAT.shp\")\n",
    "    except: \n",
    "        print(\"error: \" + fr + yr)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arcpy.overwriteoutput = True\n",
    "\n",
    "errorFires = []\n",
    "for index, row in Finalmerged[169:].iterrows():\n",
    "    fr = row.Fire\n",
    "    yr = str(row.Year)\n",
    "    JD = str(row.JD_B)\n",
    "    print(index, fr, JD)\n",
    "    rootpath = r'F:\\\\DriversFireProject\\\\NaturalNeighborResults\\\\Daily\\\\'\n",
    "    AF = rootpath + 'Dis_Shapefile\\\\' + yr + \"\\\\\" + fr + \"\\\\\" + fr + \"_\" + yr + \"_NAT.shp\"\n",
    "    SQL = \"\"\" gridcode = {}\"\"\".format(JD)\n",
    "    sel = arcpy.SelectLayerByAttribute_management(AF, 'NEW_SELECTION', SQL)\n",
    "    # Write the selected features to a new featureclass\n",
    "    \n",
    "    yrfolder =  rootpath + 'DayLayer\\\\' + yr\n",
    "    if not os.path.exists(yrfolder):\n",
    "        os.makedirs(yrfolder)\n",
    "    fireFolder = yrfolder + \"\\\\\" + fr\n",
    "    if not os.path.exists(fireFolder):\n",
    "        os.makedirs(fireFolder)\n",
    "        \n",
    "    outName = fr + \"_\" + yr + \"_\" + str(JD) +\"_NAT.shp\"\n",
    "    perimeter = arcpy.CopyFeatures_management(sel, fireFolder + \"\\\\\" + outName)\n",
    "    SHPLIST = lstFiles(fireFolder, '.shp')\n",
    "    \n",
    "    cumuyrfolder =  rootpath + 'CumuDayLayer\\\\' + yr\n",
    "    if not os.path.exists(cumuyrfolder):\n",
    "        os.makedirs(cumuyrfolder)\n",
    "    cumufireFolder = cumuyrfolder + \"\\\\\" + fr\n",
    "    if not os.path.exists(cumufireFolder):\n",
    "        os.makedirs(cumufireFolder)\n",
    "            \n",
    "    buff_yrfolder =  rootpath + 'MergedBuff\\\\' + yr\n",
    "    if not os.path.exists(buff_yrfolder):\n",
    "        os.makedirs(buff_yrfolder)\n",
    "    buff_fireFolder = buff_yrfolder + \"\\\\\" + fr\n",
    "    if not os.path.exists(buff_fireFolder):\n",
    "        os.makedirs(buff_fireFolder)\n",
    "    try: \n",
    "        if len(SHPLIST) > 1: \n",
    "            clipper = arcpy.Merge_management(SHPLIST, cumufireFolder + \"\\\\\" + outName)\n",
    "\n",
    "            Buffer_200M = arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_200m.shp\",\n",
    "                                  \"200 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\")\n",
    "            Erased_Buffer_200M = arcpy.Erase_analysis(Buffer_200M, clipper, rootpath + 'ClippedBufferLayers\\\\' + fr + \"_\" + str(JD) +\"_200m.shp\")\n",
    "\n",
    "            Buffer_1KM =arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_1Km.shp\",\n",
    "                                  \"1000 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\")\n",
    "            Erased_Buffer_1KM = arcpy.Erase_analysis(Buffer_1KM, clipper, rootpath + 'ClippedBufferLayers\\\\' + fr + \"_\" + str(JD) +\"_1Km.shp\")\n",
    "\n",
    "            Buffer_5KM =arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_5Km.shp\",\n",
    "                                  \"5000 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\")\n",
    "            Erased_Buffer_5KM = arcpy.Erase_analysis(Buffer_5KM, clipper, rootpath + 'ClippedBufferLayers\\\\' + fr + \"_\" + str(JD) +\"_5Km.shp\")\n",
    "\n",
    "            arcpy.Merge_management([Erased_Buffer_200M, Erased_Buffer_1KM, Erased_Buffer_5KM], buff_fireFolder + \"\\\\\" + outName)\n",
    "\n",
    "        else: \n",
    "            arcpy.CopyFeatures_management(SHPLIST[0], cumufireFolder + \"\\\\\" + outName)\n",
    "\n",
    "            Buffer_200M = arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_200m.shp\",\n",
    "                                  \"200 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\") \n",
    "            Buffer_1KM = arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_1Km.shp\",\n",
    "                                  \"1000 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\")     \n",
    "            Buffer_5KM = arcpy.Buffer_analysis(perimeter, rootpath + 'BufferLayers\\\\' + fr + \"_\" + yr + \"_\" + str(JD) +\"_5Km.shp\",\n",
    "                                  \"5000 METERS\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\")    \n",
    "            arcpy.Merge_management([Buffer_200M, Buffer_1KM, Buffer_5KM], buff_fireFolder + \"\\\\\" + outName)\n",
    "    except: \n",
    "        print(\"error \" + fr + \"_\" + str(JD))\n",
    "        errorFires.append(fr + \"_\" + str(JD) + \"_\" + str(index))\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFLIST = lstFiles(r\"F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\MergedBuff\", '.shp')\n",
    "len(BUFFLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/erica/Downloads/20120101_burning_index_g.tif'\n",
    "gdalwarp -ot Int16 -r bilinear -tr 0.00892857142857143 0.00892857142857143 -s_srs EPSG:4326 /home/escaduto/GridMet/Extracted_Clipped/burning_index_g/20120101_burning_index_g.tif /home/escaduto/GridMet/Resampled/burning_index_g/20120101_burning_index_g.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "# Calculate drainage flow \n",
    "\n",
    "# Set local variables\n",
    "inSurfaceRaster = r\"F:\\DriversFireProject\\Topography\\DEM\\DEM_CA.tif\"\n",
    "\n",
    "# Execute FlowDirection\n",
    "outFlowDirection = FlowDirection(inSurfaceRaster, \"NORMAL\")\n",
    "\n",
    "outFlowAccumulation = FlowAccumulation(outFlowDirection)\n",
    "outFlowAccumulation.save(r\"F:\\DriversFireProject\\Topography\\Flow_Direction\\outFlow.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFLIST = lstFiles(r\"F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\MergedBuff\", '.shp')\n",
    "BUFFLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add julian day and buff ID \n",
    "# key JD_ID\n",
    "# Merge by fire \n",
    "\n",
    "fire = [] \n",
    "pth = []\n",
    "year = []\n",
    "julianDay = []\n",
    "\n",
    "for buff in BUFFLIST: \n",
    "    nm = buff.split(\"\\\\\")\n",
    "    name = nm[-1]\n",
    "    nmm = name.split(\"_\")\n",
    "    fr = nmm[0]\n",
    "    yr = nmm[1]\n",
    "    jd = nmm[2]\n",
    "    julianDay.append(jd)\n",
    "    year.append(yr)\n",
    "    fire.append(fr)\n",
    "    pth.append(buff)\n",
    "    \n",
    "    print(name, yr)\n",
    "    \n",
    "    arcpy.AddField_management(buff, 'JD_ID', \"TEXT\")\n",
    "    with arcpy.da.UpdateCursor(buff, [\"FID\", \"JD_ID\"]) as cursor:\n",
    "        for row in cursor: \n",
    "            #print(int(row[0]))\n",
    "            row[1] = str(jd) + \"_\" + str(row[0])\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "\n",
    "BuffDF = pd.DataFrame({'Fire': fire, 'Path': pth, 'julianDay': julianDay, 'Year':year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuffDF\n",
    "\n",
    "grouped = BuffDF.groupby(['Fire', 'Year'])['Path'].apply(list).reset_index()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outpath = r'F:\\DriversFireProject\\NaturalNeighborResults\\Daily\\MergedByFire\\\\'\n",
    "\n",
    "for index, row in grouped.iterrows(): \n",
    "    pth = row.Path[0]\n",
    "    fr = row.Fire\n",
    "    yr = row.Year\n",
    "    print(row.Path[0], fr, yr) \n",
    "    '''fieldMappings = arcpy.FieldMappings()\n",
    "    fieldMappings.addTable(row.Path[0])\n",
    "    for field in fieldMappings.fields:\n",
    "        if field.name not in [\"Id\", \"JD_ID\"]:\n",
    "            fieldMappings.removeFieldMap(fieldMappings.findFieldMapIndex(field.name))'''\n",
    "    yrfolder = outpath + str(yr)\n",
    "    if not os.path.exists(yrfolder):\n",
    "        os.makedirs(yrfolder)\n",
    "    fireFolder = yrfolder + \"\\\\\" + fr\n",
    "    if not os.path.exists(fireFolder):\n",
    "        os.makedirs(fireFolder)\n",
    "    out = fireFolder + \"\\\\\"  + fr + \"_\" + yr + \"_Buff_Merged.shp\"        \n",
    "    arcpy.Merge_management(row.Path, out, fieldMappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
